# ğŸ”¬ Microplastic Detector

**AI-powered microplastic detection & water-quality dashboard**  
Works with **ESP32-CAM**, microscope cameras, or phone cameras.  
Backend (**FastAPI + OpenCV + YOLOv8**) performs detection and sizing; frontend (**React**) shows live feed, charts, and alerts. Data is logged to **CSV**.

---

## ğŸ“‘ Table of Contents
- [What this project does](#-what-this-project-does)  
- [Features](#-features)  
- [Architecture & file layout](#-architecture--file-layout)  
- [Frontend stack & tech](#-frontend-stack--tech)  
- [Backend stack & tech](#-backend-stack--tech)  
- [AI model & training](#-ai-model--training)  
- [Detection & sizing pipeline](#-detection--sizing-pipeline)  
- [Calibration (mm_per_pixel)](#-calibration-mm_per_pixel)  
- [API (endpoints & examples)](#-api-endpoints--examples)  
- [Running locally (dev)](#-running-locally-dev)  
- [Data logging (CSV)](#-data-logging-csv)  
- [Limitations & best practices](#-limitations--best-practices)  
- [Troubleshooting](#-troubleshooting)  
- [Security & production notes](#-security--production-notes)  
- [Dataset info](#-dataset-information)  
- [How the AI detects](#-how-the-ai-detects-plain-language)  
- [License & credits](#-license--credits)  

---

## ğŸ“Œ What this project does
A full-stack system to detect **microplastic particles** in images or live camera streams and present water quality metrics on a modern React dashboard.

- Accepts **image uploads** (single-frame detection)  
- Streams **live camera** (ESP32 / phone / microscope)  
- Uses **YOLOv8 object detection** for bounding-box-based sizing  
- Converts **pixel sizes â†’ mm** with a calibration factor  
- Computes **particle count** and % microplastic vs water  
- Displays results as **pie chart + stats**  
- Logs **live statistics to CSV**  
- Plays **alert sound** when plastic% exceeds threshold (10%)  

---

## âœ¨ Features
- **Upload & detect images** â†’ `/upload`, `/detect`  
- **Live camera streaming** â†’ `/esp32/video_feed`  
- **Live stats** â†’ `/esp32/stats`, `/api/latest`  
- **Annotated result images** â†’ `/image/{name}`  
- **CSV logging** of live stats (configurable interval)  
- **React dashboard** with pie chart, stats, and alerts  

---

## ğŸ— Architecture & file layout
```
microplastic-detector/
â”œâ”€ backend/
â”‚  â”œâ”€ server/
â”‚  â”‚  â”œâ”€ app.py                # FastAPI main (endpoints, logging)
â”‚  â”‚  â””â”€ esp32_handler.py
â”‚  â”œâ”€ inference/
â”‚  â”‚  â”œâ”€ detect.py             # YOLOv8 inference wrapper
â”‚  â”‚  â””â”€ utils.py              # draw_boxes, detections_to_summary
â”‚  â”œâ”€ uploads/
â”‚  â””â”€ results/
â”œâ”€ frontend/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ components/
â”‚  â”‚  â”‚  â”œâ”€ StatsPanel.jsx
â”‚  â”‚  â”‚  â””â”€ ImageViewer.jsx
â”‚  â”‚  â”œâ”€ pages/Dashboard.jsx
â”‚  â”‚  â””â”€ api/api.js
â”‚  â”œâ”€ package.json
â”‚  â””â”€ vite.config.js
â”œâ”€ runs/                        # YOLO training outputs
â”œâ”€ README.md
â””â”€ .gitignore
```

---

## ğŸ¨ Frontend stack & tech
- **React + Vite**  
- **Recharts** â†’ pie chart visualization  
- **Axios** â†’ API calls  
- **CSS** â†’ styling  

Example dependencies:
```json
{
  "dependencies": {
    "react": "^18.x",
    "react-dom": "^18.x",
    "axios": "^1.x",
    "recharts": "^2.x"
  }
}
```

---

## âš™ï¸ Backend stack & tech
- **FastAPI** (with uvicorn)  
- **YOLOv8 (Ultralytics)** for detection/training  
- **OpenCV + NumPy** for image processing  
- **Requests/urllib** for camera streams  
- **CSV logging** (live_log.csv)  

Example `requirements.txt`:
```
fastapi
uvicorn[standard]
opencv-python
numpy
ultralytics
requests
python-multipart
pillow
```

---

## ğŸ§  AI model & training
- **Model**: YOLOv8 (Ultralytics)  
- **Training**: 50 epochs, COCO/YOLO-style dataset  
- **Command**:
```bash
yolo task=detect mode=train model=yolov8s.pt data=data.yaml epochs=50 imgsz=640 batch=16
```

Dataset:
```
images/train/*.jpg, labels/train/*.txt
images/val/*.jpg, labels/val/*.txt
```

---

## ğŸ”„ Detection & sizing pipeline
1. **Upload / Stream frame**  
2. **Run YOLOv8 inference**  
3. **Bounding boxes â†’ size (px)**  
4. **Convert px â†’ mm** (if calibrated)  
5. **Compute % plastic** vs water  
6. **Save annotated image + stats**  

---

## ğŸ“ Calibration (mm_per_pixel)
1. Place object of **known length** in view  
2. Measure in **pixels**  
3. Compute:  
   ```
   mm_per_pixel = known_length_mm / measured_length_px
   ```
4. Set value in **app.py** or env var  

---

## ğŸ”Œ API (endpoints & examples)
- **POST /upload** â†’ upload image  
- **POST /detect** â†’ run detection  
- **GET /api/latest** â†’ latest stats + image  
- **GET /esp32/video_feed** â†’ MJPEG stream  
- **GET /esp32/stats** â†’ live stats  

Example:
```bash
curl -F "file=@sample.jpg" http://localhost:8000/upload
```

Response:
```json
{
  "imageUrl": "/image/annotated_sample.jpg",
  "stats": { "count": 12, "percent_plastic": 10.7 }
}
```

---

## ğŸ–¥ Running locally (dev)
### Backend
```bash
python -m venv .venv
source .venv/bin/activate        # mac/linux
.venv\Scriptsctivate           # windows

pip install -r backend/requirements.txt
uvicorn backend.server.app:app --reload --port 8000
```

### Frontend
```bash
cd frontend
npm install
npm run dev
```
Open â†’ `http://localhost:5173`

---

## ğŸ“Š Data logging (CSV)
- **File**: `backend/live_log.csv`  
- **Columns**: timestamp, objects, grams_per_ml, percent_plastic, percent_water, water_ml  
- Default: logs every **5s**  

---

## âš ï¸ Limitations & best practices
- Sizing depends on **good calibration** & resolution  
- Small particles may be **below detection threshold**  
- **False positives** from bubbles/debris possible  
- Use **GPU** for faster inference  
- Ensure **even lighting** and clean background  

---

## ğŸ›  Troubleshooting
- **No stream** â†’ check MJPEG/RTSP format  
- **CSV not writing** â†’ check file permissions  
- **Model not found** â†’ set `MODEL_PATH` to trained weights  
- **Poor detection** â†’ retrain with more samples / longer epochs  

---

## ğŸ”’ Security & production notes
- Do **not expose camera URLs** publicly  
- Add **auth** for APIs in production  
- Use **reverse proxy (nginx)** + process manager  

---

## ğŸ“‚ Dataset information
- Collect images in consistent conditions  
- Label bounding boxes (YOLO format)  
- Split â†’ **80% train / 20% val**  
- Use background images to reduce false positives  

---

## ğŸ§¾ How the AI detects (plain language)
- YOLOv8 scans the image with learned features  
- Outputs bounding boxes + confidence scores  
- Boxes â†’ size estimates â†’ particle count  
- Backend â†’ aggregates â†’ % plastic + stats  

---

## ğŸ“œ License & credits
**MIT License Â© 2025**

**Credits**:  
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)  
- [OpenCV](https://opencv.org/) & NumPy  
- [FastAPI](https://fastapi.tiangolo.com/)  
- [React](https://react.dev/) & Recharts  
